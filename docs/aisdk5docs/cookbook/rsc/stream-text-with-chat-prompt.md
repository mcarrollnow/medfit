AI SDK 5 is available now.










Menu





























































































































































































































































































































































































































































# [Stream Text with Chat Prompt](#stream-text-with-chat-prompt)

Chat completion can sometimes take a long time to finish, especially when the response is big. In such cases, it is useful to stream the chat completion to the client in real-time. This allows the client to display the new message as it is being generated by the model, rather than have users wait for it to finish.












http://localhost:3000









User: How is it going?



Assistant: All good, how may I help you?







Why is the sky blue?







Send Message






## [Client](#client)

Let's create a simple conversation between a user and a model, and place a button that will call `continueConversation`.












``` tsx
'use client';
import  from 'react';import  from './actions';import  from '@ai-sdk/rsc';
// Allow streaming responses up to 30 secondsexport const maxDuration = 30;
export default function Home() >            :           </div>        ))}      </div>
      <div>        <input          type="text"          value=          onChange=}        />        <button          onClick= = await continueConversation([              ...conversation,              ,            ]);
            let textContent = '';
            for await (const delta of readStreamableValue(newMessage)) $`;
              setConversation([                ...messages,                ,              ]);            }          }}        >          Send Message        </button>      </div>    </div>  );}
```


## [Server](#server)

Now, let's implement the `continueConversation` function that will insert the user's message into the conversation and stream back the new message.












``` typescript
'use server';
import  from 'ai';import  from '@ai-sdk/openai';import  from '@ai-sdk/rsc';
export interface Message 
export async function continueConversation(history: Message[])  = streamText();
    for await (const text of textStream) 
    stream.done();  })();
  return ;}
```

















On this page



















Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.