AI SDK 5 is available now.










Menu





























































































































































































































































































































































































































































# [Record Token Usage after Streaming User Interfaces](#record-token-usage-after-streaming-user-interfaces)

When you're streaming structured data with [`streamUI`](../../docs/reference/ai-sdk-rsc/stream-ui.html), you may want to record the token usage for billing purposes.

## [`onFinish` Callback](#onfinish-callback)

You can use the `onFinish` callback to record token usage. It is called when the stream is finished.












``` tsx
'use client';
import  from 'react';import  from './actions';import  from '@ai-sdk/rsc';import  from 'ai';
// Allow streaming responses up to 30 secondsexport const maxDuration = 30;
export default function Home()  = useActions();
  return (    <div>      <div>        >            :           </div>        ))}      </div>
      <div>        <input          type="text"          value=          onChange=}        />        <button          onClick=,            ]);
            const message = await continueConversation(input);
            setConversation((currentConversation: ClientMessage[]) => [              ...currentConversation,              message,            ]);          }}        >          Send Message        </button>      </div>    </div>  );}
```


## [Server](#server)












``` tsx
'use server';
import  from '@ai-sdk/rsc';import  from '@ai-sdk/openai';import  from 'react';import  from 'zod';import  from 'ai';
export interface ServerMessage 
export interface ClientMessage 
export async function continueConversation(  input: string,): Promise<ClientMessage> ],    text: () => ,        ]);      }
      return <div></div>;    },    tools: ),        generate: async function* () ...</div>; // [!code highlight:5]          await new Promise(resolve => setTimeout(resolve, 3000));          yield <div>Building repository ...</div>;          await new Promise(resolve => setTimeout(resolve, 2000));          return <div> deployed!</div>;        },      },    },    onFinish: () =>  = usage;      // your own logic, e.g. for saving the chat history or recording usage      console.log('Prompt tokens:', promptTokens);      console.log('Completion tokens:', completionTokens);      console.log('Total tokens:', totalTokens);    },  });
  return ;}
```













``` typescript
import  from '@ai-sdk/rsc';import  from './actions';
export const AI = createAI<ServerMessage[], ClientMessage[]>(,  initialAIState: [],  initialUIState: [],});
```













On this page



















Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.