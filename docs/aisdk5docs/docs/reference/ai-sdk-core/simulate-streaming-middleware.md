AI SDK 5 is available now.










Menu


































































































































































































































































































































































































































































































































# [`simulateStreamingMiddleware()`](#simulatestreamingmiddleware)

`simulateStreamingMiddleware` is a middleware function that simulates streaming behavior with responses from non-streaming language models. This is useful when you want to maintain a consistent streaming interface even when using models that only provide complete responses.



``` ts
import  from 'ai';
const middleware = simulateStreamingMiddleware();
```


## [Import](#import)



``` geist-overflow-scroll-y
import  from "ai"
```










## [API Signature](#api-signature)

### [Parameters](#parameters)

This middleware doesn't accept any parameters.

### [Returns](#returns)

Returns a middleware object that:

- Takes a complete response from a language model
- Converts it into a simulated stream of chunks
- Properly handles various response components including:
  - Text content
  - Reasoning (as string or array of objects)
  - Tool calls
  - Metadata and usage information
  - Warnings

### [Usage Example](#usage-example)



``` ts
import  from 'ai';import  from 'ai';import  from 'ai';
// Example with a non-streaming modelconst result = streamText(),  prompt: 'Your prompt here',});
// Now you can use the streaming interfacefor await (const chunk of result.fullStream) 
```


## [How It Works](#how-it-works)

The middleware:

1.  Awaits the complete response from the language model
2.  Creates a `ReadableStream` that emits chunks in the correct sequence
3.  Simulates streaming by breaking down the response into appropriate chunk types
4.  Preserves all metadata, reasoning, tool calls, and other response properties
















On this page

































Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.