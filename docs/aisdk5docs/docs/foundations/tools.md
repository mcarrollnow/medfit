AI SDK 5 is available now.










Menu






















































































































































































































































































































































# [Tools](#tools)

While [large language models (LLMs)](overview.html#large-language-models) have incredible generation capabilities, they struggle with discrete tasks (e.g. mathematics) and interacting with the outside world (e.g. getting the weather).

Tools are actions that an LLM can invoke. The results of these actions can be reported back to the LLM to be considered in the next response.

For example, when you ask an LLM for the "weather in London", and there is a weather tool available, it could call a tool with London as the argument. The tool would then fetch the weather data and return it to the LLM. The LLM can then use this information in its response.

## [What is a tool?](#what-is-a-tool)

A tool is an object that can be called by the model to perform a specific task. You can use tools with [`generateText`](../reference/ai-sdk-core/generate-text.html) and [`streamText`](../reference/ai-sdk-core/stream-text.html) by passing one or more tools to the `tools` parameter.

A tool consists of three properties:

- **`description`**: An optional description of the tool that can influence when the tool is picked.
- **`inputSchema`**: A [Zod schema](#schema-specification-and-validation-with-zod) or a [JSON schema](../reference/ai-sdk-core/json-schema.html) that defines the input required for the tool to run. The schema is consumed by the LLM, and also used to validate the LLM tool calls.
- **`execute`**: An optional async function that is called with the arguments from the tool call.




`streamUI` uses UI generator tools with a `generate` function that can return React components.



If the LLM decides to use a tool, it will generate a tool call. Tools with an `execute` function are run automatically when these calls are generated. The output of the tool calls are returned using tool result objects.

You can automatically pass tool results back to the LLM using [multi-step calls](../ai-sdk-core/tools-and-tool-calling.html#multi-step-calls) with `streamText` and `generateText`.

## [Schemas](#schemas)

Schemas are used to define the parameters for tools and to validate the [tool calls](../ai-sdk-core/tools-and-tool-calling.html).








pnpm







npm







yarn







bun








``` geist-overflow-scroll-y
pnpm add zod
```












You can then specify a Zod schema, for example:



``` ts
import z from 'zod';
const recipeSchema = z.object(),    ),    steps: z.array(z.string()),  }),});
```





You can also use schemas for structured output generation with [`generateObject`](../reference/ai-sdk-core/generate-object.html) and [`streamObject`](../reference/ai-sdk-core/stream-object.html).



## [Toolkits](#toolkits)

When you work with tools, you typically need a mix of application specific tools and general purpose tools. There are several providers that offer pre-built tools as **toolkits** that you can use out of the box:








## [Learn more](#learn-more)

The AI SDK Core [Tool Calling](../ai-sdk-core/tools-and-tool-calling.html) and [Agents](../agents/overview.html) documentation has more information about tools and tool calling.
















On this page

























Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.