AI SDK 5 is available now.










Menu






















































































































































































































































































































































































































































































# [LM Studio Provider](#lm-studio-provider)



## [Setup](#setup)

The LM Studio provider is available via the `@ai-sdk/openai-compatible` module as it is compatible with the OpenAI API. You can install it with






pnpm







npm







yarn







bun








``` geist-overflow-scroll-y
pnpm add @ai-sdk/openai-compatible
```












## [Provider Instance](#provider-instance)

To use LM Studio, you can create a custom provider instance with the `createOpenAICompatible` function from `@ai-sdk/openai-compatible`:



``` ts
import  from '@ai-sdk/openai-compatible';
const lmstudio = createOpenAICompatible();
```








## [Language Models](#language-models)




``` ts
const model = lmstudio('llama-3.2-1b');
```



### [Example](#example)

You can use LM Studio language models to generate text with the `generateText` function:



``` ts
import  from '@ai-sdk/openai-compatible';import  from 'ai';
const lmstudio = createOpenAICompatible();
const  = await generateText();
```


LM Studio language models can also be used with `streamText`.

## [Embedding Models](#embedding-models)




``` ts
const model = lmstudio.textEmbeddingModel(  'text-embedding-nomic-embed-text-v1.5',);
```


### [Example - Embedding a Single Value](#example---embedding-a-single-value)



``` tsx
import  from '@ai-sdk/openai-compatible';import  from 'ai';
const lmstudio = createOpenAICompatible();
// 'embedding' is a single embedding object (number[])const  = await embed();
```


### [Example - Embedding Many Values](#example---embedding-many-values)

When loading data, e.g. when preparing a data store for retrieval-augmented generation (RAG), it is often useful to embed many values at once (batch embedding).

The AI SDK provides the [`embedMany`](../../docs/reference/ai-sdk-core/embed-many.html) function for this purpose. Similar to `embed`, you can use it with embeddings models, e.g. `lmstudio.textEmbeddingModel('text-embedding-nomic-embed-text-v1.5')` or `lmstudio.textEmbeddingModel('text-embedding-bge-small-en-v1.5')`.



``` tsx
import  from '@ai-sdk/openai-compatible';import  from 'ai';
const lmstudio = createOpenAICompatible();
// 'embeddings' is an array of embedding objects (number[][]).// It is sorted in the same order as the input values.const  = await embedMany();
```

















On this page









































Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.