AI SDK 5 is available now.










Menu






















































































































































































































































































































































































































































































# [LangSmith Observability](#langsmith-observability)


Use of LangChain's open-source frameworks is not necessary.







## [Setup](#setup)












pnpm







npm







yarn







bun








``` geist-overflow-scroll-y
pnpm add @ai-sdk/openai langsmith
```












Next, set required environment variables.



``` bash
export LANGCHAIN_TRACING=trueexport LANGCHAIN_API_KEY=<your-api-key>
export OPENAI_API_KEY=<your-openai-api-key> # The examples use OpenAI (replace with your selected provider)
```


## [Trace Logging](#trace-logging)

To start tracing, you will need to import and call the `wrapAISDK` method at the start of your code:



``` ts
import  from '@ai-sdk/openai';import * as ai from 'ai';
import  from 'langsmith/experimental/vercel';
const  =  wrapAISDK(ai);
await generateText();
```



You can also trace runs with tool calls:



``` ts
import * as ai from 'ai';import  from 'ai';import  from '@ai-sdk/openai';import  from 'zod';
import  from 'langsmith/experimental/vercel';
const  =  wrapAISDK(ai);
await generateText(,  ],  tools: ),      execute: async () =>        `User $ has the following orders: 1`,    }),    viewTrackingInformation: tool(),      execute: async () =>        `Here is the tracking information for $`,    }),  },  stopWhen: stepCountIs(5),});
```



You can use other AI SDK methods exactly as you usually would.

### [With `traceable`](#with-traceable)

You can wrap `traceable` calls around AI SDK calls or within AI SDK tool calls. This is useful if you want to group runs together in LangSmith:



``` ts
import * as ai from 'ai';import  from 'ai';import  from '@ai-sdk/openai';import  from 'zod';
import  from 'langsmith/traceable';import  from 'langsmith/experimental/vercel';
const  =  wrapAISDK(ai);
const wrapper = traceable(  async (input: string) =>  = await generateText(,      ],      tools: ),          execute: async () =>            `User $ has the following orders: 1`,        }),        viewTrackingInformation: tool(),          execute: async () =>            `Here is the tracking information for $`,        }),      },      stopWhen: stepCountIs(5),    });    return text;  },  ,);
await wrapper('What are my orders and where are they? My user ID is 123.');
```



## [Tracing in serverless environments](#tracing-in-serverless-environments)


## [Further reading](#further-reading)

For more examples and instructions for setting up tracing in specific environments, see the links below:


And once you've set up LangSmith tracing for your project, try gathering a dataset and evaluating it:

















On this page






























Vercel delivers the infrastructure and developer experience you need to ship reliable AI-powered applications at scale.

Trusted by industry leaders:















#### Resources




#### More




#### About Vercel




#### Legal







Â© 2025 Vercel, Inc.